{
  "cells": [
    {
      "cell_type": "raw",
      "id": "c6a1a7b1",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Data Analysis\"\n",
        "subtitle: \"Comprehensive Data Cleaning & Exploratory Analysis of Job Market Trends\"\n",
        "author:\n",
        "  - name: Jiexin (Avery) Fan\n",
        "   affiliations:\n",
        "      - id: bu\n",
        "        name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "  - name: Ivan Villasmil\n",
        "    affiliations:\n",
        "      - id: bu\n",
        "        name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "  - name: Jiayin Liu\n",
        "    affiliations:\n",
        "      - id: bu\n",
        "        name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "number-sections: true\n",
        "date: '2025-11-29'\n",
        "date-modified: today\n",
        "date-format: long\n",
        "format: \n",
        "  pdf: default\n",
        "  docx: default\n",
        "  html:\n",
        "    theme: cerulean\n",
        "    toc: true\n",
        "    toc-depth: 2\n",
        "    number-sections: true\n",
        "    df-print: paged\n",
        "execute:\n",
        "  echo: true\n",
        "  eval: true\n",
        "  freeze: auto\n",
        "jupyter: python3\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d28f1b41-3c0d-45f5-965b-7311d8fd317f",
      "metadata": {},
      "source": [
        "# Business Running Case; Evaluating Personal Job Market Prospects in 2025"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da605a9e",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Load required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import plotly.graph_objects as go\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, split, explode, regexp_replace, transform, when\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import col, monotonically_increasing_id, to_date, pow\n",
        "import re\n",
        "\n",
        "# Set random seed and default renderer for Plotly\n",
        "np.random.seed(950)\n",
        "pio.renderers.default = \"notebook\"\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n",
        "\n",
        "# Upload CSV file into a Spark DataFrame\n",
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"./data/lightcast_job_postings.csv\")\n",
        "\n",
        "# Register DataFrame as a Temporary SQL table\n",
        "df.createOrReplaceTempView(\"job_postings\")\n",
        "\n",
        "# Verify Data: Display Schema (column names & data types)\n",
        "# print(\"---This is Diagnostic check, No need to print it in the final doc---\") # Comment line when rendering the submission\n",
        "# df.printSchema() # Comment line when rendering the submission\n",
        "\n",
        "# Typecast columns to double\n",
        "df = df.withColumn(\"SALARY\", col(\"SALARY\").cast(\"double\"))\n",
        "df = df.withColumn(\"SALARY_TO\", col(\"SALARY_TO\").cast(\"double\"))\n",
        "df = df.withColumn(\"SALARY_FROM\", col(\"SALARY_FROM\").cast(\"double\"))\n",
        "df = df.withColumn(\"MIN_YEARS_EXPERIENCE\", col(\"MIN_YEARS_EXPERIENCE\").cast(\"double\"))\n",
        "df = df.withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(\"double\"))\n",
        "df = df.withColumn(\"DURATION\", col(\"DURATION\").cast(\"double\"))\n",
        "df = df.withColumn(\"MODELED_DURATION\", col(\"MODELED_DURATION\").cast(\"double\"))\n",
        "df = df.withColumn(\"IS_INTERNSHIP\", col(\"IS_INTERNSHIP\").cast(\"double\"))\n",
        "df = df.withColumn(\"COMPANY_IS_STAFFING\", col(\"COMPANY_IS_STAFFING\").cast(\"double\"))\n",
        "\n",
        "# Typecast dates to date type\n",
        "df = df.withColumn(\"POSTED\", to_date(col(\"POSTED\"), \"M/d/yyyy\"))\n",
        "df = df.withColumn(\"EXPIRED\", to_date(col(\"EXPIRED\"), \"M/d/yyyy\"))\n",
        "df = df.withColumn(\"LAST_UPDATED_DATE\", to_date(col(\"LAST_UPDATED_DATE\"), \"M/d/yyyy\"))\n",
        "df = df.withColumn(\"MODELED_EXPIRED\", to_date(col(\"MODELED_EXPIRED\"), \"M/d/yyyy\"))\n",
        "\n",
        "# Verify Data: Display first five rows\n",
        "# print(\"---This is Diagnostic check, No need to print it in the final doc---\") # Comment line when rendering the submission\n",
        "# df.show(5)  # Comment line when rendering the submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b19fcc49",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Load required libraries\n",
        "from pyspark.sql.functions import col, trim, when, pow\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler \n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Take subset of relevant columns\n",
        "relevant_columns = [\"SALARY\", \"MIN_YEARS_EXPERIENCE\", \"EDUCATION_LEVELS_NAME\", \"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\", \"DURATION\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\"]\n",
        "\n",
        "df_analysis = df.select(*relevant_columns)\n",
        "\n",
        "# Drop rows with NAs in relevant columns  *** AVOID DROPPING TO ACCESS ALL DATA ***\n",
        "# df_analysis = df_analysis.dropna(subset=[\n",
        "#   \"SALARY\", \"MIN_YEARS_EXPERIENCE\", \n",
        "#   \"EDUCATION_LEVELS_NAME\", \"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\",\n",
        "#   \"DURATION\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\"\n",
        "# ])\n",
        "\n",
        "# Preview cleaned dataframe\n",
        "# df_analysis.show(5, truncate=False)\n",
        "\n",
        "# Identify unique values in categorical columns\n",
        "categorical_columns = [\n",
        "  \"EDUCATION_LEVELS_NAME\", \n",
        "  \"EMPLOYMENT_TYPE_NAME\", \n",
        "  \"REMOTE_TYPE_NAME\",\n",
        "  \"IS_INTERNSHIP\", \n",
        "  \"COMPANY_IS_STAFFING\"\n",
        "]\n",
        "\n",
        "# Preview unique values in categorical columns\n",
        "# for col_name in categorical_columns:\n",
        "#     print(f\"Unique values in {col_name}:\")\n",
        "#     df_analysis.select(col_name).distinct().show(truncate=False)\n",
        "\n",
        "# Redefine unique values in REMOTE_TYPE_NAME to be: 'Remote': Remote; 'Hybrid Remote': Hybrid; 'None': Onsite; 'Not Remote': Onsite\n",
        "df_analysis = df_analysis.withColumn(\"REMOTE_GROUP\",\n",
        "    when(trim(col(\"REMOTE_TYPE_NAME\")) == \"Remote\", \"Remote\")\n",
        "    .when(trim(col(\"REMOTE_TYPE_NAME\")) == \"Hybrid Remote\", \"Hybrid\")\n",
        "    .when(trim(col(\"REMOTE_TYPE_NAME\")) == \"Not Remote\", \"Onsite\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\").isNull(), \"Onsite\")\n",
        "    .otherwise(\"Onsite\") \n",
        ")\n",
        "\n",
        "# Redefine unique values in EMPLOYMENT_TYPE_NAME to be: Full-time, Part-time, Flexible\n",
        "df_analysis = df_analysis.withColumn(\"EMPLOYMENT_GROUP\",\n",
        "    when(trim(col(\"EMPLOYMENT_TYPE_NAME\")) == \"Full-time (> 32 hours)\", \"Full-time\")\n",
        "    .when(trim(col(\"EMPLOYMENT_TYPE_NAME\")) == \"Part-time (â‰¤ 32 hours)\", \"Part-time\")\n",
        "    .when(trim(col(\"EMPLOYMENT_TYPE_NAME\")) == \"Part-time / full-time\", \"Flexible\")\n",
        "    .when(col(\"EMPLOYMENT_TYPE_NAME\").isNull(), \"Full-time\")\n",
        "    .otherwise(\"Flexible\")\n",
        ")\n",
        "\n",
        "# Preview unique values in EMPLOYMENT_TYPE_NAME\n",
        "# df_analysis.select(\"EMPLOYMENT_TYPE_NAME\").distinct().show(truncate=False)\n",
        "# df_analysis.show(5, truncate=False)\n",
        "\n",
        "# Typecast MIN_YEARS_EXPERIENCE to categories: 0-1: Internship/Entry Level; 1-3: Junior; 3-5: Mid-Level; 5-10: Senior; 10+: Expert\n",
        "df_analysis = df_analysis.withColumn(\"MIN_YEARS_EXPERIENCE_GROUP\",\n",
        "  when(col(\"MIN_YEARS_EXPERIENCE\").between(0, 1), \"Internship/Entry Level\")\n",
        "    .when(col(\"MIN_YEARS_EXPERIENCE\").between (1, 3), \"Junior\")\n",
        "    .when(col(\"MIN_YEARS_EXPERIENCE\").between(3, 5), \"Mid-Level\")\n",
        "    .when(col(\"MIN_YEARS_EXPERIENCE\").between(5, 10), \"Senior\")\n",
        "    .otherwise(\"Expert\")\n",
        ")\n",
        "\n",
        "# Replace NULL in MIN_YEARS_EXPERIENCE to \"0\"\n",
        "df_analysis= df_analysis.withColumn(\"MIN_YEARS_EXPERIENCE\",\n",
        "    when(col(\"MIN_YEARS_EXPERIENCE\").isNull(), 0)\n",
        "    .otherwise(col(\"MIN_YEARS_EXPERIENCE\")))\n",
        "\n",
        "# Preview typacasted values in MIN_YEARS_EXPERIENCE_GROUP\n",
        "# df_analysis.select(\"MIN_YEARS_EXPERIENCE_GROUP\").distinct().show(truncate=False)\n",
        "# df_analysis.show(5, truncate=False)\n",
        "\n",
        "# 3. Replace NULL & zeros in Duration to \"1\"\n",
        "df_analysis = df_analysis.withColumn(\"DURATION\",\n",
        "    when(col(\"DURATION\").isNull(), 1)\n",
        "    .when(col(\"DURATION\") == 0, 1)\n",
        "    .otherwise(col(\"DURATION\")))\n",
        "\n",
        "# Preview cleaned MIN_YEARS_EXPERIENCE_GROUP\n",
        "# df_analysis.select(\"MIN_YEARS_EXPERIENCE_GROUP\").distinct().show(truncate=False)\n",
        "# df_analysis.show(5, truncate=False)\n",
        "\n",
        "# 4. Remove [\\n \\n] characters from EDUCATION_LEVELS_NAME\n",
        "df_analysis = df_analysis.withColumn(\n",
        "    \"EDUCATION_LEVELS_CLEAN\",\n",
        "    F.trim(F.regexp_replace(F.col(\"EDUCATION_LEVELS_NAME\"), r'[\\[\\]\\n\"]', ''))\n",
        ").drop(\"EDUCATION_LEVELS_NAME\")\n",
        "\n",
        "# Preview cleaned EDUCATION_LEVELS_NAME\n",
        "# df_analysis.select(\"EDUCATION_LEVELS_CLEAN\").distinct().show(truncate=False)\n",
        "# df_analysis.show(5, truncate=False)\n",
        "\n",
        "# df_analysis.select(\"EMPLOYMENT_GROUP\").distinct().show(truncate=False)\n",
        "# df_analysis.show(5, truncate=False)\n",
        "\n",
        "# Drop reformated/redundant columns\n",
        "df_analysis = df_analysis.drop(\"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\", \"EDUCATION_LEVELS_NAME\")\n",
        "df_analysis.show(5, truncate=False)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3",
      "path": "/usr/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
